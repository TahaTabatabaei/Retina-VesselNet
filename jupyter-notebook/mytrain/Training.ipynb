{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-rocket",
   "metadata": {},
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "planned-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  8 13:35:09 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650       WDDM | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P0               15W /  N/A|      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "2.10.0\n",
      "detected GPUs by TF:  []\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import os\n",
    "import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"     #use GPU-0 \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"detected GPUs by TF: \",tf.config.list_physical_devices('GPU'))\n",
    "gpus=tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\taha\\code\\Retina-VesselNet\\jupyter-notebook\\mytrain\\Training.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m device_name \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtest\u001b[39m.\u001b[39mgpu_device_name()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m device_name \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/device:GPU:0\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mSystemError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mGPU device not found\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFound GPU at: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(device_name))\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-processor",
   "metadata": {},
   "source": [
    "## Process and Generate the Training Image Patch 数据预处理与训练图像块生成\n",
    "\n",
    "### setting of dataset path 设置部分\n",
    "\n",
    "- set the parameter and dataset dir (设定数据集的位置以及超参数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\taha\\code\\Retina-VesselNet\\DRIVE\\training\\images\\21_training.tif\n",
      "number of training images: 14\n",
      "number of valid images: 6\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "patch_size=48        # patch image size (图像块大小)\n",
    "patch_num=1000        # sample number of one training image  (每张训练图像采样的图像块数量)\n",
    "patch_threshold=25   # threshold for the patch, the smaller threshoold, the less vessel in the patch (采样阈值，数值越小，图像块内的血管面积越小)\n",
    "TRAIN_OR_VAL=0.7\n",
    "dataset_path='E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\'   # modify the dataset_path to your own dir（将dataset_path修改至你自己的路径）\n",
    "\n",
    "train_dir=dataset_path+\"training\\\\\"\n",
    "\n",
    "train_image_dir=train_dir+\"images\\\\\"\n",
    "train_mask_dir=train_dir+\"mask\\\\\"\n",
    "train_groundtruth_dir=train_dir+\"1st_manual\\\\\"\n",
    "train_patch_dir=train_dir+\"patch\\\\\"\n",
    "\n",
    "\n",
    "# train_image_path_list=glob(train_image_dir+\"*.tif\")\n",
    "train_image_path_list = [os.path.normpath(i) for i in glob(train_image_dir+\"*.tif\")]\n",
    "print(train_image_path_list[0])\n",
    "\n",
    "\n",
    "val_image_path_list=random.sample(train_image_path_list,int(len(train_image_path_list)*(1-TRAIN_OR_VAL)))\n",
    "train_image_path_list=[i for i in train_image_path_list if i not in val_image_path_list]\n",
    "\n",
    "print(\"number of training images:\",len(train_image_path_list))\n",
    "print(\"number of valid images:\",len(val_image_path_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-socket",
   "metadata": {},
   "source": [
    "### Image Preprocess （图像预处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inside-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_normalized(imgs,mask):\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs-imgs_mean)/imgs_std\n",
    "    for i in range(imgs.shape[2]):\n",
    "        imgs_normalized[:,:,i] = ((imgs_normalized[:,:,i] - np.min(imgs_normalized[:,:,i])) / (np.max(imgs_normalized[:,:,i])-np.min(imgs_normalized[:,:,i])))*255\n",
    "    return imgs_normalized\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "#adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\n",
    "def clahe_equalized(imgs):\n",
    "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "  imgs_equalized = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_equalized[:,:,i] = clahe.apply(np.array(imgs[:,:,i], dtype = np.uint8))\n",
    "  return imgs_equalized\n",
    "\n",
    "def normalized(imgs):\n",
    "  imgs_normalized =np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_normalized[:,:,i] =cv2.equalizeHist(imgs[:,:,i])\n",
    "  return imgs_normalized\n",
    "\n",
    "def adjust_gamma(imgs, gamma=1.0):\n",
    "  invGamma = 1.0 / gamma\n",
    "  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "  # apply gamma correction using the lookup table\n",
    "  new_imgs = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    new_imgs[:,:,i] = cv2.LUT(np.array(imgs[:,:,i], dtype = np.uint8), table)\n",
    "  return new_imgs\n",
    "\n",
    "def preprocess(image,mask):\n",
    "  \n",
    "  assert np.max(mask)==1\n",
    "  image=np.array(image)\n",
    "  image[:,:,0]=image[:,:,0]*mask\n",
    "  image[:,:,1]=image[:,:,1]*mask\n",
    "  image[:,:,2]=image[:,:,2]*mask\n",
    "  \n",
    "  image=restrict_normalized(image,mask)\n",
    "  image=clahe_equalized(image)\n",
    "  image=adjust_gamma(image,1.2)\n",
    "  image=image/255.0\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-cooler",
   "metadata": {},
   "source": [
    "### Generate Image/Mask Patches （图像块生成部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interracial-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate the training patches: 100%|██████████| 14/14 [00:27<00:00,  2.00s/it]\n",
      "Generate the val patches: 100%|██████████| 6/6 [00:10<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "def check_coord(x,y,h,w,patch_size):\n",
    "  if x-patch_size/2>0 and x+patch_size/2<h and y-patch_size/2>0 and y+patch_size/2<w:\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "def image2patch(image_path,patch_num,patch_size,training=True,show=True):\n",
    "  image_name=image_path.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "\n",
    "  image=plt.imread(image_path)\n",
    "\n",
    "  groundtruth=plt.imread(train_groundtruth_dir+image_name+\"_manual1.gif\")\n",
    "  groundtruth=np.where(groundtruth>0,1,0)\n",
    "\n",
    "  mask=plt.imread(train_mask_dir+image_name+\"_training_mask.gif\")\n",
    "  mask=np.where(mask>0,1,0)\n",
    "  \n",
    "  image=preprocess(image,mask)\n",
    "  #image_binary=0.8*image[:,:,1]+0.2*image[:,:,2]  \n",
    "\n",
    "  image_show=image.copy()\n",
    "  groundtruth_show=np.zeros_like(image)\n",
    "  groundtruth_show[:,:,0]=groundtruth.copy()\n",
    "  groundtruth_show[:,:,1]=groundtruth.copy()\n",
    "  groundtruth_show[:,:,2]=groundtruth.copy()\n",
    "\n",
    "  sample_count=0\n",
    "  sample_index=0\n",
    "  \n",
    "  sample_point=np.where(groundtruth==1)     # generate sample point (生成采样中心点)\n",
    "\n",
    "  state = np.random.get_state()      # shuffle the coord (打乱顺序，模拟随机采样)\n",
    "  np.random.shuffle(sample_point[0])\n",
    "  np.random.set_state(state)\n",
    "  np.random.shuffle(sample_point[1])\n",
    "\n",
    "  patch_image_list=[]\n",
    "  patch_groundtruth_list=[]\n",
    "\n",
    "  while sample_count<patch_num and sample_index<len(sample_point[0]):\n",
    "    x,y=sample_point[0][sample_index],sample_point[1][sample_index]\n",
    "    if check_coord(x,y,image.shape[0],image.shape[1],patch_size):\n",
    "      if np.sum(mask[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2])>patch_threshold:     #select according to the threshold\n",
    "       \n",
    "        patch_image_binary=image[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2,:]   # patch image\n",
    "        patch_groundtruth=groundtruth[x-patch_size//2:x+patch_size//2,y-patch_size//2:y+patch_size//2]       # patch mask\n",
    "        #patch_image_binary=np.asarray(0.25*patch_image[:,:,2]+0.75*patch_image[:,:,1])         # B*0.25+G*0.75, which enhance the vessel (增强血管的对比度)\n",
    "        patch_groundtruth=np.where(patch_groundtruth>0,255,0)\n",
    "    \n",
    "        #patch_image_binary =cv2.equalizeHist((patch_image_binary*255.0).astype(np.uint8))/255.0\n",
    "        \n",
    "        patch_image_list.append(patch_image_binary)    # patch image\n",
    "        patch_groundtruth_list.append(patch_groundtruth)             # patch mask\n",
    "        if show:\n",
    "          cv2.rectangle(image_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)  #draw the illustration\n",
    "          cv2.rectangle(groundtruth_show, (y-patch_size//2,x-patch_size//2,), (y+patch_size//2,x+patch_size//2), (0,1,0), 2)\n",
    "        sample_count+=1\n",
    "    \n",
    "    if show:                                 # visualize the sample process(可视化采样过程，会很慢！)\n",
    "      plt.figure(figsize=(15,15))\n",
    "      plt.title(\"processing: %s\"%image_name)\n",
    "      plt.subplot(121)\n",
    "      plt.imshow(image_show,cmap=plt.cm.gray)   # processd image\n",
    "      plt.subplot(122)\n",
    "      plt.imshow(groundtruth_show,cmap=plt.cm.gray)  #groundtruth of the image, patch is showed as the green square (绿色的方框表示采样的图像块)\n",
    "      plt.show()\n",
    "      display.clear_output(wait=True)\n",
    "    sample_index+=1\n",
    "\n",
    "  for i in range(len(patch_image_list)):\n",
    "    if training==True:\n",
    "        plt.imsave(train_patch_dir+image_name+\"-\"+str(i)+\"-img.jpg\",patch_image_list[i])\n",
    "        #print(patch_mask_list[i])\n",
    "        plt.imsave(train_patch_dir+image_name+\"-\"+str(i)+\"-groundtruth.jpg\",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)\n",
    "    else:\n",
    "        plt.imsave(train_patch_dir+image_name+\"_\"+str(i)+\"_val_img.jpg\",patch_image_list[i])\n",
    "        #print(patch_mask_list[i])\n",
    "        plt.imsave(train_patch_dir+image_name+\"_\"+str(i)+\"_val_groundtruth.jpg\",(patch_groundtruth_list[i]/225.0).astype(np.uint8),cmap = plt.cm.gray)\n",
    "\n",
    "# delete original patch images (删除已有的图像块数据)\n",
    "if not os.path.exists(train_patch_dir):\n",
    "  os.mkdir(train_patch_dir)\n",
    "else:\n",
    "  shutil.rmtree(train_patch_dir)\n",
    "  os.mkdir(train_patch_dir)    \n",
    "\n",
    "    \n",
    "# generate patch images (生成图像块数据)\n",
    "for i in tqdm(range(len(train_image_path_list)),desc=\"Generate the training patches: \"):\n",
    "  image2patch(train_image_path_list[i],patch_num,patch_size,training=True,show=False)  # set show=True to visualize the sample process, which is much slower than show=False\n",
    "\n",
    "for i in tqdm(range(len(val_image_path_list)),desc=\"Generate the val patches: \"):\n",
    "  image2patch(val_image_path_list[i],patch_num,patch_size,training=False,show=False)  # set show=True to visualize the sample process, which is much slower than show=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-conviction",
   "metadata": {},
   "source": [
    "## [Part-II] Model Defination 定义U-net模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prescription-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import AveragePooling2D,Conv2DTranspose,Input,Add,Conv2D, BatchNormalization,LeakyReLU, Activation, MaxPool2D, Dropout, Flatten, Dense,UpSampling2D,Concatenate,Softmax\n",
    "\n",
    "# define the model under eager mode\n",
    "\n",
    "class LinearTransform(tf.keras.Model):\n",
    "  def __init__(self, name=\"LinearTransform\"):\n",
    "    super(LinearTransform, self).__init__(self,name=name)\n",
    "\n",
    "    self.conv_r=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_g=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "    self.conv_b=Conv2D(1,kernel_size=3,strides=1,padding='same',use_bias=False)\n",
    "\n",
    "    self.pool_rc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_gc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "    self.pool_bc=AveragePooling2D(pool_size=(patch_size,patch_size),strides=1)\n",
    "        \n",
    "    self.bn=BatchNormalization()\n",
    "    self.sigmoid=Activation('sigmoid')\n",
    "    self.softmax=Activation('softmax')\n",
    "\n",
    "  def call(self, input,training=True):\n",
    "    r,g,b=input[:,:,:,0:1],input[:,:,:,1:2],input[:,:,:,2:3]\n",
    "\n",
    "    rs=self.conv_r(r)\n",
    "    gs=self.conv_g(g)\n",
    "    bs=self.conv_r(b)\n",
    "\n",
    "    rc=tf.reshape(self.pool_rc(rs),[-1,1])\n",
    "    gc=tf.reshape(self.pool_gc(gs),[-1,1])\n",
    "    bc=tf.reshape(self.pool_bc(bs),[-1,1])\n",
    "\n",
    "    merge=Concatenate(axis=-1)([rc,gc,bc])\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=tf.expand_dims(merge,axis=1)\n",
    "    merge=self.softmax(merge)\n",
    "    merge=tf.repeat(merge,repeats=48,axis=2)\n",
    "    merge=tf.repeat(merge,repeats=48,axis=1)\n",
    "\n",
    "    r=r*(1+self.sigmoid(rs))\n",
    "    g=g*(1+self.sigmoid(gs))\n",
    "    b=b*(1+self.sigmoid(bs))\n",
    "\n",
    "    output=self.bn(merge[:,:,:,0:1]*r+merge[:,:,:,1:2]*g+merge[:,:,:,2:3]*b,training=training)\n",
    "    return output\n",
    "\n",
    "class ResBlock(tf.keras.Model):\n",
    "  def __init__(self,out_ch,residual_path=False,stride=1):\n",
    "    super(ResBlock,self).__init__(self)\n",
    "    self.residual_path=residual_path\n",
    "        \n",
    "    self.conv1=Conv2D(out_ch,kernel_size=3,strides=stride,padding='same', use_bias=False,data_format=\"channels_last\")\n",
    "    self.bn1=BatchNormalization()\n",
    "    self.relu1=LeakyReLU()#Activation('leaky_relu')\n",
    "        \n",
    "    self.conv2=Conv2D(out_ch,kernel_size=3,strides=1,padding='same', use_bias=False,data_format=\"channels_last\")\n",
    "    self.bn2=BatchNormalization()\n",
    "        \n",
    "    if residual_path:\n",
    "      self.conv_shortcut=Conv2D(out_ch,kernel_size=1,strides=stride,padding='same',use_bias=False)\n",
    "      self.bn_shortcut=BatchNormalization()\n",
    "        \n",
    "    self.relu2=LeakyReLU()#Activation('leaky_relu')\n",
    "        \n",
    "  def call(self,x,training=True):\n",
    "    xs=self.relu1(self.bn1(self.conv1(x),training=training))\n",
    "    xs=self.bn2(self.conv2(xs),training=training)\n",
    "\n",
    "    if self.residual_path:\n",
    "      x=self.bn_shortcut(self.conv_shortcut(x),training=training)\n",
    "    #print(x.shape,xs.shape)\n",
    "    xs=x+xs\n",
    "    return self.relu2(xs)\n",
    "\n",
    "\n",
    "class Unet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Unet,self).__init__(self)\n",
    "    self.conv_init=LinearTransform()\n",
    "    self.resinit=ResBlock(16,residual_path=True)\n",
    "    self.up_sample=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resup=ResBlock(32,residual_path=True)\n",
    "    \n",
    "    self.pool1=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down1=ResBlock(64,residual_path=True)\n",
    "    self.resblock_down11=ResBlock(64,residual_path=False)\n",
    "    self.pool2=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down2=ResBlock(128,residual_path=True)\n",
    "    self.resblock_down21=ResBlock(128,residual_path=False)\n",
    "    self.pool3=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock_down3=ResBlock(256,residual_path=True)\n",
    "    self.resblock_down31=ResBlock(256,residual_path=False)\n",
    "    self.pool4=MaxPool2D(pool_size=(2,2))\n",
    "\n",
    "    self.resblock=ResBlock(512,residual_path=True)\n",
    "\n",
    "    self.unpool3=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up3=ResBlock(256,residual_path=True)\n",
    "    self.resblock_up31=ResBlock(256,residual_path=False)\n",
    "\n",
    "    self.unpool2=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up2=ResBlock(128,residual_path=True)\n",
    "    self.resblock_up21=ResBlock(128,residual_path=False)\n",
    "\n",
    "    self.unpool1=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock_up1=ResBlock(64,residual_path=True)\n",
    "    \n",
    "    self.unpool_final=UpSampling2D(size=(2,2),interpolation='bilinear')\n",
    "    self.resblock2=ResBlock(32,residual_path=True)\n",
    "    \n",
    "    self.pool_final=MaxPool2D(pool_size=(2,2))\n",
    "    self.resfinal=ResBlock(32)\n",
    "    \n",
    "    self.conv_final=Conv2D(1,kernel_size=1,strides=1,padding='same',use_bias=False)\n",
    "    self.bn_final=BatchNormalization()\n",
    "    self.act=Activation('sigmoid')\n",
    "\n",
    "  def call(self,x,training=True):\n",
    "    x_linear=self.conv_init(x,training=training)\n",
    "    x=self.resinit(x_linear,training=training)\n",
    "    x=self.up_sample(x)\n",
    "    x=self.resup(x,training=training)\n",
    "    \n",
    "    stage1=self.pool1(x)\n",
    "    stage1=self.resblock_down1(stage1,training=training)\n",
    "    stage1=self.resblock_down11(stage1,training=training)\n",
    "\n",
    "    stage2=self.pool2(stage1)\n",
    "    stage2=self.resblock_down2(stage2,training=training)\n",
    "    stage2=self.resblock_down21(stage2,training=training)\n",
    "\n",
    "    stage3=self.pool3(stage2)\n",
    "    stage3=self.resblock_down3(stage3,training=training)\n",
    "    stage3=self.resblock_down31(stage3,training=training)\n",
    "\n",
    "    stage4=self.pool4(stage3)\n",
    "    stage4=self.resblock(stage4,training=training)\n",
    "\n",
    "    stage3=Concatenate(axis=3)([stage3,self.unpool3(stage4)])\n",
    "    stage3=self.resblock_up3(stage3,training=training)\n",
    "    stage3=self.resblock_up31(stage3,training=training)\n",
    "\n",
    "    stage2=Concatenate(axis=3)([stage2,self.unpool2(stage3)])\n",
    "    stage2=self.resblock_up2(stage2,training=training)\n",
    "    stage2=self.resblock_up21(stage2,training=training)\n",
    "\n",
    "    stage1=Concatenate(axis=3)([stage1,self.unpool1(stage2)])\n",
    "    stage1=self.resblock_up1(stage1,training=training)\n",
    "    \n",
    "    x=Concatenate(axis=3)([x,self.unpool_final(stage1)])\n",
    "    x=self.resblock2(x,training=training)\n",
    "    \n",
    "    x=self.pool_final(x)\n",
    "    x=self.resfinal(x,training=training)\n",
    "    \n",
    "    seg_result=self.act(self.bn_final(self.conv_final(x),training=training))\n",
    "    \n",
    "    return x_linear,seg_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-somerset",
   "metadata": {},
   "source": [
    "## [Part-III] Training Model 训练模型\n",
    "\n",
    "### setting part （设置超参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organic-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=200\n",
    "VAL_TIME=2\n",
    "LR=0.0003\n",
    "BATCH_SIZE=64\n",
    "\n",
    "checkpoint_path=dataset_path+\"ckpt\\\\\"\n",
    "log_path=dataset_path+\"logs\\\\\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "  os.mkdir(checkpoint_path)\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "  os.mkdir(log_path)\n",
    "\n",
    "# use tensorboard to visualize the loss,acc,... (使用tensorboard观察各类指标变化)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-surgeon",
   "metadata": {},
   "source": [
    "### Training/Valid DataLoader (加载训练/测试数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "settled-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 14000\n",
      "['E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\29-132-img.jpg', 'E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\34-781-img.jpg']\n",
      "['E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\29-132-groundtruth.jpg', 'E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\34-781-groundtruth.jpg']\n",
      "['E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\22_0_val_img.jpg', 'E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\22_100_val_img.jpg']\n",
      "['E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\22_0_val_groundtruth.jpg', 'E:\\\\taha\\\\code\\\\Retina-VesselNet\\\\DRIVE\\\\training\\\\patch\\\\22_100_val_groundtruth.jpg']\n"
     ]
    }
   ],
   "source": [
    "def load_image_groundtruth(img_path,groundtruth_path):\n",
    "  img=tf.io.read_file(img_path)\n",
    "  img=tf.image.decode_jpeg(img,channels=3)\n",
    "  img=tf.image.resize(img,[patch_size,patch_size])\n",
    "\n",
    "  groundtruth=tf.io.read_file(groundtruth_path)\n",
    "  groundtruth=tf.image.decode_jpeg(groundtruth,channels=1)\n",
    "  \n",
    "  # data argument (数据增强部分)\n",
    "  if random.uniform(0,1)>=0.5:\n",
    "    img=tf.image.flip_left_right(img)\n",
    "    groundtruth=tf.image.flip_left_right(groundtruth)\n",
    "\n",
    "#   if random.uniform(0,1)>=0.5:\n",
    "#     seeds=random.uniform(0,1)\n",
    "#     img=tf.image.central_crop(img,seeds)\n",
    "#     groundtruth=tf.image.central_crop(groundtruth,seeds)\n",
    "\n",
    "  img=tf.image.resize(img,[patch_size,patch_size])\n",
    "  groundtruth=tf.image.resize(groundtruth,[patch_size,patch_size])\n",
    "    \n",
    "  img/=255.0\n",
    "  groundtruth=(groundtruth+40)/255.0\n",
    "  groundtruth=tf.cast(groundtruth,dtype=tf.uint8)\n",
    "\n",
    "  return img,groundtruth\n",
    "\n",
    "\n",
    "train_patch_img_path_list=sorted(glob(train_patch_dir+\"*-*-img.jpg\"))\n",
    "train_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*-*-groundtruth.jpg\"))\n",
    "train_patch_img_path_list,train_patch_groundtruth_path_list=shuffle(train_patch_img_path_list,train_patch_groundtruth_path_list,random_state=0)\n",
    "\n",
    "# make sure that img-list and mask-list is in order (确保打乱后的image-mask还是对应的) \n",
    "print(len(train_patch_img_path_list),len(train_patch_groundtruth_path_list))\n",
    "print(train_patch_img_path_list[:2])\n",
    "print(train_patch_groundtruth_path_list[:2])\n",
    "\n",
    "val_patch_img_path_list=sorted(glob(train_patch_dir+\"*_*_val_img.jpg\"))\n",
    "val_patch_groundtruth_path_list=sorted(glob(train_patch_dir+\"*_*_val_groundtruth.jpg\"))\n",
    "\n",
    "print(val_patch_img_path_list[:2])\n",
    "print(val_patch_groundtruth_path_list[:2])\n",
    "\n",
    "# Training Dataloader\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_patch_img_path_list,train_patch_groundtruth_path_list))\n",
    "train_dataset=train_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# VAL Dataloader\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val_patch_img_path_list,val_patch_groundtruth_path_list))\n",
    "val_dataset=val_dataset.map(load_image_groundtruth,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset =val_dataset.shuffle(buffer_size=1300).prefetch(BATCH_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-scanning",
   "metadata": {},
   "source": [
    "### Load and Compile the Model (加载并编译模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "received-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Unet()\n",
    "\n",
    "# Learning rate and optimizer （学习率调整和优化器）\n",
    "cosine_decay = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=LR, first_decay_steps=12000,t_mul=1000,m_mul=0.5,alpha=1e-5)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay)\n",
    "\n",
    "# loss function （损失函数）\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# metric record （性能指标记录器）\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc=tf.keras.metrics.Mean(name='train_acc')\n",
    "current_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_acc=tf.keras.metrics.Mean(name='val_acc')\n",
    "val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "\n",
    "# checkpoint （模型存档管理器）\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "#ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "# tensorboard writer （Tensorboard记录器）\n",
    "log_dir=log_path+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-extent",
   "metadata": {},
   "source": [
    "### Dice Loss & Dice Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outstanding-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true,y_pred,smooth=1.):\n",
    "  y_true=tf.cast(y_true,dtype=tf.float32)\n",
    "  y_true_f = K.flatten(y_true)\n",
    "  y_pred_f = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_f * y_pred_f)\n",
    "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "  return (1-dice(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-wells",
   "metadata": {},
   "source": [
    "### Traing Step & Valid Step\n",
    "\n",
    "training function and validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southern-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(step,patch,groundtruth):\n",
    "  with tf.GradientTape() as tape:\n",
    "        \n",
    "    linear,pred_seg=model(patch,training=True)\n",
    "    losses = dice_loss(groundtruth, pred_seg)\n",
    "    \n",
    "  # calculate the gradient （求梯度）\n",
    "  grads = tape.gradient(losses, model.trainable_variables)\n",
    "  # bp (反向传播) \n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  # record the training loss and accuracy (记录loss和准确率)\n",
    "  train_loss.update_state(losses)\n",
    "  train_acc.update_state(dice(groundtruth, pred_seg))\n",
    "\n",
    "\n",
    "\n",
    "def val_step(step,patch,groundtruth):\n",
    " \n",
    "  linear,pred_seg=model(patch,training=False)\n",
    "  losses = dice_loss(groundtruth, pred_seg)\n",
    "    \n",
    "  # record the val loss and accuracy (记录loss和准确率)\n",
    "  val_loss.update_state(losses)\n",
    "  val_acc.update_state(dice(groundtruth, pred_seg))\n",
    "  \n",
    "  tf.summary.image(\"image\",patch,step=step)\n",
    "  tf.summary.image(\"image transform\",linear,step=step)\n",
    "  tf.summary.image(\"groundtruth\",groundtruth*255,step=step)\n",
    "  tf.summary.image(\"pred\",pred_seg,step=step)\n",
    "  log_writer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-location",
   "metadata": {},
   "source": [
    "### Main Function of Training (训练主程序)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prepared-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, batch 0, loss:0.7477, dice:0.2523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\taha\\code\\Retina-VesselNet\\jupyter-notebook\\mytrain\\Training.ipynb Cell 22\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# training （训练部分）\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m tstep, (patch,groundtruth) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   train_step(lr_step,patch,groundtruth)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   \u001b[39m# tf.summary.scalar(\"learning_rate\", optimizer._decayed_lr(tf.float32).numpy(), step=lr_step)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39mepoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, batch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, loss:\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, dice:\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, tstep, train_loss\u001b[39m.\u001b[39mresult(), train_acc\u001b[39m.\u001b[39mresult()),end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32me:\\taha\\code\\Retina-VesselNet\\jupyter-notebook\\mytrain\\Training.ipynb Cell 22\u001b[0m line \u001b[0;36mtrain_step\u001b[1;34m(step, patch, groundtruth)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(step,patch,groundtruth):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     linear,pred_seg\u001b[39m=\u001b[39mmodel(patch,training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     losses \u001b[39m=\u001b[39m dice_loss(groundtruth, pred_seg)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39m# calculate the gradient （求梯度）\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    567\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;32me:\\taha\\code\\Retina-VesselNet\\jupyter-notebook\\mytrain\\Training.ipynb Cell 22\u001b[0m line \u001b[0;36mUnet.call\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m stage3\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresblock_down31(stage3,training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m stage4\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool4(stage3)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m stage4\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresblock(stage4,training\u001b[39m=\u001b[39;49mtraining)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m stage3\u001b[39m=\u001b[39mConcatenate(axis\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)([stage3,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munpool3(stage4)])\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m stage3\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresblock_up3(stage3,training\u001b[39m=\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    567\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[1;32me:\\taha\\code\\Retina-VesselNet\\jupyter-notebook\\mytrain\\Training.ipynb Cell 22\u001b[0m line \u001b[0;36mResBlock.call\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m,x,training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m   xs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x),training\u001b[39m=\u001b[39mtraining))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m   xs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(xs),training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/taha/code/Retina-VesselNet/jupyter-notebook/mytrain/Training.ipynb#X30sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual_path:\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:290\u001b[0m, in \u001b[0;36mConv.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    286\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compiled_convolution_op(\n\u001b[0;32m    287\u001b[0m         inputs, tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolution_op(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[0;32m    292\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[0;32m    293\u001b[0m     output_rank \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:262\u001b[0m, in \u001b[0;36mConv.convolution_op\u001b[1;34m(self, inputs, kernel)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m     tf_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding\n\u001b[1;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mconvolution(\n\u001b[0;32m    263\u001b[0m     inputs,\n\u001b[0;32m    264\u001b[0m     kernel,\n\u001b[0;32m    265\u001b[0m     strides\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrides),\n\u001b[0;32m    266\u001b[0m     padding\u001b[39m=\u001b[39;49mtf_padding,\n\u001b[0;32m    267\u001b[0m     dilations\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation_rate),\n\u001b[0;32m    268\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tf_data_format,\n\u001b[0;32m    269\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    270\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1182\u001b[0m, in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnn.convolution\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   1173\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvolution_v2\u001b[39m(  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     dilations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1181\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1182\u001b[0m   \u001b[39mreturn\u001b[39;00m convolution_internal(\n\u001b[0;32m   1183\u001b[0m       \u001b[39minput\u001b[39;49m,  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m       filters,\n\u001b[0;32m   1185\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[0;32m   1186\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   1187\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   1188\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[0;32m   1189\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1314\u001b[0m, in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1311\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m     op \u001b[39m=\u001b[39m conv1d\n\u001b[1;32m-> 1314\u001b[0m   \u001b[39mreturn\u001b[39;00m op(\n\u001b[0;32m   1315\u001b[0m       \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   1316\u001b[0m       filters,\n\u001b[0;32m   1317\u001b[0m       strides,\n\u001b[0;32m   1318\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   1319\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   1320\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[0;32m   1321\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m   \u001b[39mif\u001b[39;00m channel_index \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:2788\u001b[0m, in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2784\u001b[0m input_rank \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m   2785\u001b[0m \u001b[39mif\u001b[39;00m input_rank \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m input_rank \u001b[39m<\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[0;32m   2786\u001b[0m   \u001b[39m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[39;00m\n\u001b[0;32m   2787\u001b[0m   \u001b[39m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[39;00m\n\u001b[1;32m-> 2788\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mconv2d(\n\u001b[0;32m   2789\u001b[0m       \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   2790\u001b[0m       \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mfilters,\n\u001b[0;32m   2791\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[0;32m   2792\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   2793\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   2794\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[0;32m   2795\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2796\u001b[0m \u001b[39mreturn\u001b[39;00m squeeze_batch_dims(\n\u001b[0;32m   2797\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   2798\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2805\u001b[0m     inner_rank\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m   2806\u001b[0m     name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\siedt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1199\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   1198\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1199\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   1200\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mConv2D\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, \u001b[39mfilter\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrides\u001b[39;49m\u001b[39m\"\u001b[39;49m, strides,\n\u001b[0;32m   1201\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39muse_cudnn_on_gpu\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_cudnn_on_gpu, \u001b[39m\"\u001b[39;49m\u001b[39mpadding\u001b[39;49m\u001b[39m\"\u001b[39;49m, padding,\n\u001b[0;32m   1202\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mexplicit_paddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, explicit_paddings, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_format,\n\u001b[0;32m   1203\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mdilations\u001b[39;49m\u001b[39m\"\u001b[39;49m, dilations)\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   1205\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_step=0\n",
    "last_val_loss=2e10\n",
    "with log_writer.as_default():\n",
    "  for epoch in range(EPOCHS):\n",
    "    # renew the recorder （重置记录项）\n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    val_acc.reset_states()\n",
    "  \n",
    "    # training （训练部分）\n",
    "    for tstep, (patch,groundtruth) in enumerate(train_dataset):\n",
    "      train_step(lr_step,patch,groundtruth)\n",
    "    \n",
    "      # tf.summary.scalar(\"learning_rate\", optimizer._decayed_lr(tf.float32).numpy(), step=lr_step)\n",
    "      print('\\repoch {}, batch {}, loss:{:.4f}, dice:{:.4f}'.format(epoch + 1, tstep, train_loss.result(), train_acc.result()),end=\"\")\n",
    "      lr_step+=1\n",
    "\n",
    "    if (epoch + 1) % VAL_TIME == 0:\n",
    "      #valid (验证部分)\n",
    "      for vstep, (patch,groundtruth) in enumerate(val_dataset):\n",
    "            \n",
    "        val_step(lr_step,patch,groundtruth)\n",
    "        \n",
    "      print('\\repoch {}, batch {}, train_loss:{:.4f}, train_dice:{:.4f}, val_loss:{:.4f}, val_dice:{:.4f}'.format(epoch + 1, vstep, train_loss.result(), train_acc.result(),val_loss.result(), val_acc.result()),end=\"\")\n",
    "      # tf.summary.scalar(\"val_loss\", val_loss.result(), step=epoch)\n",
    "      # tf.summary.scalar(\"val_acc\", val_acc.result(), step=epoch)\n",
    "    \n",
    "      if val_loss.result()<last_val_loss:\n",
    "        ckpt.save(checkpoint_path)\n",
    "        last_val_loss=val_loss.result()\n",
    "    print(\"\")\n",
    "    # tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch)\n",
    "    # tf.summary.scalar(\"train_acc\", train_acc.result(), step=epoch)\n",
    "    log_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-steering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
